## mawcd : Codec (compressor-Decompressor) using MAWs (Minimal Absent Words)
===========================================================================

*mawcd* is a tool that compresses (lossless) a given file and decompress a compressed a file to recreate the original .
Currently it takes only the files in FASTA format (proper FASTA currently disabled for the experiments).

The tool is based on the terminology and the algorithm described in the paper titled
[**Name of the paper**](https://link to the paper)
by *Panagiotis Charalampopoulos, Gabriele Fici, Ritu Kundu, and Solon P. Pissis*
This is work in progress.

To compile mawcd, please follow the instructions given in file `INSTALL.md`


## Usage of the tool: 
 Usage: mawcd <options>
```
 Standard (Mandatory):
  -m, --mode 			<str> 		`AD' for anti-dictionary creation 
						 or `COM' for compression of single file 
						 or `DECOM' for decompression of single file 
						 or `BCOM' for compression of many files 
						 or `BDECOM' for decompression of many files. 

  -a, --alphabet 		 <str> 	 	 `DNA' for nucleotide sequences
						 or `PROT' for protein  sequences 
						 or `SEL' for user-defined 
						 or `GEN' for general (ASCII). 

  -i, --input-file 		 <str> 	 	 Input file  name  
						(uncompressed file when mode is `COM'; compressed file when mode is `DECOM'; 
						 a file containing names of the files to compress or decompress in batch mode [one name on each line]).

  -d, --antidictionary-file 	 <str> 	 	 Anti-dictionary file  name 
						(created when mode is `AD' and read when mode is any other).

 Additional:
  -s, --selected-alphabet 	 <str> 	 	 case-sensitive alphabet  (required when alphabet is SEL). 
```

 **Example:** 

You can try the tool for compression with the given sample files (`sample` folder) via
```sh
./bin/mawcd -m AD -a DNA -i sample/input1.txt -d sample/ad
```

```sh
./bin/mawcd -m COM -a DNA -i sample/input1.txt -d sample/ad
```
It will compress the file input2.txt (which mimics the Fasta format) to create the compressed file com2.txt and an anti-dictionary ad2.txt (All in the `sample` folder).

You can try the tool for decompression with the output generated by the command above on the sample files (`sample` folder), via
```sh
./bin/mawcd -m DECOM -a DNA -i sample/input1.txt.com -d sample/ad
```
It will decompress the compressed file com2.txt to create the decompressed original file decom2.txt (which will be same as the original file) using the anti-dictionary ad2.txt (All in the `sample` folder).


## Alphabet
 * DNA: ACGTN (irrespective of case)
 * PROT: ACDEFGHIKLMNPQRSTUVWY (irrespective of case)
 * GEN: All graphical or space characters
 * SEL: User given case-sensitive alphabet


## Compression
- In batch mode: Input file is contains the names of all the files to be compressed (one per line).
- Input file to be compressed is read in blocks (currently 1MB).
 * Currently, he file is assumed to be representing only one sequence.
 * All new lines and spaces are ignored (except in the case of GEN alphabet).
 * Each block is encoded, compressed, packed, and stored in output file.
  
- Output file (compressed) : same name as that of input file with an added extension ('.com' currently).
 * Compressed File Format (binary):
  + First 4 bytes represent the length of the original sequence.
  + Following which are compressed encoded sequence (of '0' and '1') packed into bytes.

## Decompression
* In batch mode: Input file is contains the names of all the files to be decompressed (one per line).
* Input file (assumed to be in compressed format) is read in blocks (currently 1MB).
 - Each block is decompressed, decoded, and stored in output file.
   
* Output file (decompressed) : same name as that of input file with an added extension ('.decom' currently).

## Anti-dictionary
- Anti-dictionary file is in the following binary format:
 * First one byte: 0: Actual Key_size: from 1 to 32 (space used by each key is given by KEY_SIZE)
   + Next one byte: 1: number of keys of one byte in ad_0
   + Next one byte: 2: number of keys of one byte in ad_1
   + Next two bytes: 3 and 4: number of keys of two bytes in ad_0
   + Next two bytes: 5 and 6: number of keys of two bytes in ad_1
   + Next four bytes: 7 to 10: number of keys of four bytes in ad_0
   + Next four bytes: 11 to 14: number of keys of four bytes in ad_1
   + From there on, the keys of ad_0 start: keys in ad_0 of size 1, then size 2, then 3, and then 4 (size in bytes, number as above)
   + Following them are the keys for ad_1: keys in ad_1 of size 1, then size 2, then 3, and then 4 (size in bytes, number as above)
 * Currently, it assume that the writing and reading machine has the same Endian-conventions. And the experiments script assumes it to be 'little' endian.

 


## Experiments

You can run the experiments via
```sh
python3 ./scripts/experiments.py 
```


* CURING 
  - All files with the ".fa.gz" in "data" folder are extracted.
  - All files are cured to to save only the sequence.
  - A single file consisting of all the sequences from each data-set is created.
  - Original file is deleted. 
  - Each filename is kept intact to extract info later on. Only ".cured" is appended to the filenames.

* RUNNING mawcd 
  - Anti-dictionary is created for the merged sequence. Time is noted.
  - Each sequence is then compressed, decompressed, and verified.
  - Info like compression-time, decompression-time, original-file-size, compressed-file-size is noted.
  - The files are generated in the `result` folder.

* RUNNING GZIP
  - Each sequence is then compressed using gzip and file-size is stored.

* WRITING stats
  - Collected parameters are written down in`experiments.stats` file are created in the `result` folder.



## Problems/TODO

 * To find better flat-representation (for storage) of the anti-dictionary.
 * Use SDSL to directly construct csa from the file (for creating anti-dictionary). {Check if Solon's tool needs only Fasta format}.
 * Take care of the endian-ness in writing ints (size of the orginal sequence etc.).
 * Client doesn't need SDSL or maw tool.
 * See if packed is needed before compression
 * Improve finding the number of occurrences of MAws using SA rather than pattern matching.

## External Libraries
 * To find the number of occurrences of the longest proper prefix of maws (used to find the optimal length of the keys of dictionary), following library has been used:
   + [sdsl](https://github.com/simongog/sdsl-lite)

 * For generating MAWs, following tool has been used:
  + [maw] (https://github.com/solonas13/maw)


